version: '3.9'

services:
  rag-support-app:
    build: .
    container_name: rag_support_app
    ports:
      - "8503:8501"  # Streamlit UI
      - "8010:8010"  # FastAPI webhook service
    environment:
      # Ollama on the host machine (Docker Desktop: host.docker.internal works)
      - OLLAMA_HOST=http://host.docker.internal:11434

      # OpenAI API key
      - OPENAI_API_KEY=${OPENAI_API_KEY}

      # Streamlit configuration
      - STREAMLIT_SERVER_ADDRESS=0.0.0.0
      - STREAMLIT_SERVER_PORT=8501

      # FastAPI webhook configuration
      - WEBHOOK_SECRET=${WEBHOOK_SECRET:-}
      - YT_BASE_URL=${YT_BASE_URL:-}
      - YT_TOKEN=${YT_TOKEN:-}

      # Chroma DB path
      - CHROMA_DIR=/app/data/chroma
      - PERSIST_DIR=/app/data/chroma

      # Retrieval settings
      - TOP_K=${TOP_K:-5}
      - MAX_DISTANCE=${MAX_DISTANCE:-0.9}
      - PER_PARENT_DISPLAY=${PER_PARENT_DISPLAY:-1}
      - PER_PARENT_PROMPT=${PER_PARENT_PROMPT:-3}
      - STITCH_MAX_CHARS=${STITCH_MAX_CHARS:-1500}
      - MEM_CAP=${MEM_CAP:-2}

      # Memory collection (optional)
      - ENABLE_MEMORY=${ENABLE_MEMORY:-0}
      - MEM_COLLECTION=${MEM_COLLECTION:-memories}
    volumes:
      - ./data_docker:/app/data
      - ./.streamlit:/app/.streamlit:ro
      - ./.app_prefs.json:/app/.app_prefs.json
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
